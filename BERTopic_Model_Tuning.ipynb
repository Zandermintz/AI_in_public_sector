{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic\n",
      "  Using cached bertopic-0.16.0-py2.py3-none-any.whl (154 kB)\n",
      "Collecting numpy>=1.20.0\n",
      "  Using cached numpy-1.26.2-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Collecting hdbscan>=0.8.29\n",
      "  Using cached hdbscan-0.8.33-cp311-cp311-macosx_10_9_universal2.whl\n",
      "Collecting umap-learn>=0.5.0\n",
      "  Using cached umap-learn-0.5.5.tar.gz (90 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pandas>=1.1.5\n",
      "  Using cached pandas-2.1.4-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
      "Collecting scikit-learn>=0.22.2.post1\n",
      "  Using cached scikit_learn-1.3.2-cp311-cp311-macosx_12_0_arm64.whl (9.4 MB)\n",
      "Collecting tqdm>=4.41.1\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Collecting sentence-transformers>=0.4.1\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting plotly>=4.7.0\n",
      "  Using cached plotly-5.18.0-py3-none-any.whl (15.6 MB)\n",
      "Collecting cython<3,>=0.27\n",
      "  Using cached Cython-0.29.37-py2.py3-none-any.whl (989 kB)\n",
      "Collecting scipy>=1.0\n",
      "  Using cached scipy-1.11.4-cp311-cp311-macosx_12_0_arm64.whl (29.7 MB)\n",
      "Collecting joblib>=1.0\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv3/lib/python3.11/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: packaging in ./venv3/lib/python3.11/site-packages (from plotly>=4.7.0->bertopic) (23.2)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Using cached transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "Collecting torch>=1.6.0\n",
      "  Using cached torch-2.1.2-cp311-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.16.2-cp311-cp311-macosx_11_0_arm64.whl (1.5 MB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.99-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Using cached huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\n",
      "Collecting numba>=0.51.2\n",
      "  Using cached numba-0.58.1-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Collecting pynndescent>=0.5\n",
      "  Using cached pynndescent-0.5.11-py3-none-any.whl (55 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0\n",
      "  Using cached llvmlite-0.41.1-cp311-cp311-macosx_11_0_arm64.whl (28.8 MB)\n",
      "Requirement already satisfied: six>=1.5 in ./venv3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.12.25-cp311-cp311-macosx_11_0_arm64.whl (291 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.0/291.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.19,>=0.14\n",
      "  Using cached tokenizers-0.15.0-cp311-cp311-macosx_11_0_arm64.whl (2.5 MB)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Using cached safetensors-0.4.1-cp311-cp311-macosx_11_0_arm64.whl (426 kB)\n",
      "Collecting click\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Using cached Pillow-10.1.0-cp311-cp311-macosx_11_0_arm64.whl (3.3 MB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_universal2.whl (17 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: sentencepiece, pytz, mpmath, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, tenacity, sympy, safetensors, regex, pyyaml, pillow, numpy, networkx, MarkupSafe, llvmlite, joblib, idna, fsspec, filelock, cython, click, charset-normalizer, certifi, scipy, requests, plotly, pandas, numba, nltk, jinja2, torch, scikit-learn, huggingface-hub, torchvision, tokenizers, pynndescent, hdbscan, umap-learn, transformers, sentence-transformers, bertopic\n",
      "\u001b[33m  DEPRECATION: umap-learn is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for umap-learn ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[33m  DEPRECATION: sentence-transformers is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for sentence-transformers ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed MarkupSafe-2.1.3 bertopic-0.16.0 certifi-2023.11.17 charset-normalizer-3.3.2 click-8.1.7 cython-0.29.37 filelock-3.13.1 fsspec-2023.12.2 hdbscan-0.8.33 huggingface-hub-0.20.1 idna-3.6 jinja2-3.1.2 joblib-1.3.2 llvmlite-0.41.1 mpmath-1.3.0 networkx-3.2.1 nltk-3.8.1 numba-0.58.1 numpy-1.26.2 pandas-2.1.4 pillow-10.1.0 plotly-5.18.0 pynndescent-0.5.11 pytz-2023.3.post1 pyyaml-6.0.1 regex-2023.12.25 requests-2.31.0 safetensors-0.4.1 scikit-learn-1.3.2 scipy-1.11.4 sentence-transformers-2.2.2 sentencepiece-0.1.99 sympy-1.12 tenacity-8.2.3 threadpoolctl-3.2.0 tokenizers-0.15.0 torch-2.1.2 torchvision-0.16.2 tqdm-4.66.1 transformers-4.36.2 typing-extensions-4.9.0 tzdata-2023.3 umap-learn-0.5.5 urllib3-2.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentence-transformers in ./venv3/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in ./venv3/lib/python3.11/site-packages (from sentence-transformers) (4.36.2)\n",
      "Requirement already satisfied: tqdm in ./venv3/lib/python3.11/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in ./venv3/lib/python3.11/site-packages (from sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: torchvision in ./venv3/lib/python3.11/site-packages (from sentence-transformers) (0.16.2)\n",
      "Requirement already satisfied: numpy in ./venv3/lib/python3.11/site-packages (from sentence-transformers) (1.26.2)\n",
      "Requirement already satisfied: scikit-learn in ./venv3/lib/python3.11/site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in ./venv3/lib/python3.11/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: nltk in ./venv3/lib/python3.11/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in ./venv3/lib/python3.11/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in ./venv3/lib/python3.11/site-packages (from sentence-transformers) (0.20.1)\n",
      "Requirement already satisfied: filelock in ./venv3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.12.2)\n",
      "Requirement already satisfied: requests in ./venv3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in ./venv3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in ./venv3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./venv3/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./venv3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./venv3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
      "Requirement already satisfied: click in ./venv3/lib/python3.11/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv3/lib/python3.11/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv3/lib/python3.11/site-packages (from torchvision->sentence-transformers) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv3/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv3/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.7.2-cp311-cp311-macosx_11_0_arm64.whl (6.5 MB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.10-cp311-cp311-macosx_11_0_arm64.whl (26 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.8-cp311-cp311-macosx_11_0_arm64.whl (41 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl (128 kB)\n",
      "Collecting thinc<8.3.0,>=8.1.8\n",
      "  Using cached thinc-8.2.2-cp311-cp311-macosx_11_0_arm64.whl (778 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Using cached wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Using cached srsly-2.4.8-cp311-cp311-macosx_11_0_arm64.whl (488 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0\n",
      "  Using cached weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Using cached typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Using cached smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./venv3/lib/python3.11/site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./venv3/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4\n",
      "  Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in ./venv3/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in ./venv3/lib/python3.11/site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv3/lib/python3.11/site-packages (from spacy) (23.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./venv3/lib/python3.11/site-packages (from spacy) (1.26.2)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting pydantic-core==2.14.6\n",
      "  Downloading pydantic_core-2.14.6-cp311-cp311-macosx_11_0_arm64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.1 in ./venv3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Using cached blis-0.7.11-cp311-cp311-macosx_11_0_arm64.whl (1.1 MB)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./venv3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0\n",
      "  Using cached cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv3/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Installing collected packages: cymem, wasabi, typer, spacy-loggers, spacy-legacy, smart-open, pydantic-core, murmurhash, langcodes, cloudpathlib, catalogue, blis, annotated-types, srsly, pydantic, preshed, confection, weasel, thinc, spacy\n",
      "Successfully installed annotated-types-0.6.0 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 pydantic-2.5.3 pydantic-core-2.14.6 smart-open-6.4.0 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.2 typer-0.9.0 wasabi-1.1.2 weasel-0.3.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: hdbscan in ./venv3/lib/python3.11/site-packages (0.8.33)\n",
      "Requirement already satisfied: cython<3,>=0.27 in ./venv3/lib/python3.11/site-packages (from hdbscan) (0.29.37)\n",
      "Requirement already satisfied: numpy>=1.20 in ./venv3/lib/python3.11/site-packages (from hdbscan) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.0 in ./venv3/lib/python3.11/site-packages (from hdbscan) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in ./venv3/lib/python3.11/site-packages (from hdbscan) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.0 in ./venv3/lib/python3.11/site-packages (from hdbscan) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv3/lib/python3.11/site-packages (from scikit-learn>=0.20->hdbscan) (3.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: umap-learn in ./venv3/lib/python3.11/site-packages (0.5.5)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv3/lib/python3.11/site-packages (from umap-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.3.1 in ./venv3/lib/python3.11/site-packages (from umap-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in ./venv3/lib/python3.11/site-packages (from umap-learn) (1.3.2)\n",
      "Requirement already satisfied: numba>=0.51.2 in ./venv3/lib/python3.11/site-packages (from umap-learn) (0.58.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in ./venv3/lib/python3.11/site-packages (from umap-learn) (0.5.11)\n",
      "Requirement already satisfied: tqdm in ./venv3/lib/python3.11/site-packages (from umap-learn) (4.66.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in ./venv3/lib/python3.11/site-packages (from numba>=0.51.2->umap-learn) (0.41.1)\n",
      "Requirement already satisfied: joblib>=0.11 in ./venv3/lib/python3.11/site-packages (from pynndescent>=0.5->umap-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv3/lib/python3.11/site-packages (from scikit-learn>=0.22->umap-learn) (3.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Installing necessary libraries for OpenAlex API and BERTopic pipeline\n",
    "\n",
    "%pip install bertopic #BERTopic:\n",
    "%pip install sentence-transformers #Sentence transformers\n",
    "%pip install spacy #Spacy\n",
    "%pip install hdbscan #HDBSCAN\n",
    "%pip install umap-learn #UMAP\n",
    "%pip install sklearn #SKlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below BERT model was fine-tuned for producing topic representations for the **_abstract_list_clean_en_** corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using BERTopic for Topic Modeling\n",
    "#check supporting documentation: https://maartengr.github.io/BERTopic/index.html\n",
    "\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "\n",
    "# Step 1 - Extract embeddings\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(n_neighbors=5, n_components=3, min_dist=0.2, metric='cosine', low_memory=False)\n",
    "\n",
    "# Step 3 - Cluster reduced embeddings. lever to adjust number of clusters / topics\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=5, metric='euclidean', cluster_selection_method='leaf', prediction_data=True)\n",
    "\n",
    "# Step 4 - Tokenize topics\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "\n",
    "# Step 6 - (Optional) Fine-tune topic representations with MMR. Decreases redundancy and improves diversity of keywords.\n",
    "representation_model = MaximalMarginalRelevance(diversity=0.5)\n",
    "\n",
    "# All steps together\n",
    "topic_model = BERTopic(\n",
    "  embedding_model=embedding_model,          # Step 1 - Extract embeddings\n",
    "  umap_model=umap_model,                    # Step 2 - Reduce dimensionality\n",
    "  hdbscan_model=hdbscan_model,              # Step 3 - Cluster reduced embeddings\n",
    "  vectorizer_model=vectorizer_model,        # Step 4 - Tokenize topics\n",
    "  ctfidf_model=ctfidf_model,                # Step 5 - Create topic representation\n",
    "  #seed_topic_list = keywords_list,          # Step 5a - Add keyword list based on KeyBERT output & finetuning\n",
    "  representation_model=representation_model,# Step 6 - (Optional) Fine-tune topic represenation \n",
    "  calculate_probabilities=True,        \n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "##Saving the model\n",
    "model_path = \"BERT_AI_Policy_topic_model\"\n",
    "topic_model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below BERT model was fine-tuned for producing topic representations for the **_list_of_abs_** corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 11:04:57,676 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
     ]
    }
   ],
   "source": [
    "##Using BERTopic for Topic Modeling\n",
    "#check supporting documentation: https://maartengr.github.io/BERTopic/index.html\n",
    "\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import MaximalMarginalRelevance\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "\n",
    "# Step 1 - Extract embeddings\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(n_neighbors=3, n_components=3, min_dist=0.1, metric='cosine', low_memory=False)\n",
    "\n",
    "# Step 3 - Cluster reduced embeddings. lever to adjust number of clusters / topics\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=3, metric='euclidean', cluster_selection_method='leaf', prediction_data=True)\n",
    "\n",
    "# Step 4 - Tokenize topics\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "\n",
    "# Step 6 - (Optional) Fine-tune topic representations with MMR. Decreases redundancy and improves diversity of keywords.\n",
    "representation_model = MaximalMarginalRelevance(diversity=0.5)\n",
    "\n",
    "# All steps together\n",
    "topic_model = BERTopic(\n",
    "  embedding_model=embedding_model,          # Step 1 - Extract embeddings\n",
    "  umap_model=umap_model,                    # Step 2 - Reduce dimensionality\n",
    "  hdbscan_model=hdbscan_model,              # Step 3 - Cluster reduced embeddings\n",
    "  vectorizer_model=vectorizer_model,        # Step 4 - Tokenize topics\n",
    "  ctfidf_model=ctfidf_model,                # Step 5 - Create topic representation\n",
    "  #seed_topic_list = keywords_list,          # Step 5a - Add keyword list based on KeyBERT output & finetuning\n",
    "  representation_model=representation_model,# Step 6 - (Optional) Fine-tune topic represenation \n",
    "  calculate_probabilities=True,        \n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "##Saving the model\n",
    "model_path = \"BERT_AI_Policy_topic_model_reduced\"\n",
    "topic_model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
